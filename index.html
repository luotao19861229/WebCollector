<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Webcollector : A java crawler for infomation collection.">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Webcollector</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/CrawlScript/WebCollector">View on GitHub</a>

          <h1 id="project_title">Webcollector</h1>
          <h2 id="project_tagline">A java crawler for infomation collection.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/CrawlScript/WebCollector/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/CrawlScript/WebCollector/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a name="webcollector" class="anchor" href="#webcollector"><span class="octicon octicon-link"></span></a>WebCollector</h1>

<p>WebCollector is an open source Java crawler which provides some simple interfaces for crawling the Web。You can setup a multi-threaded web crawler in 5 minutes!</p>

<h3>
<a name="demo" class="anchor" href="#demo"><span class="octicon octicon-link"></span></a>DEMO</h3>

<p>This DEMO extracts all the questions asked  at <a href="http://www.zhihu.com/">http://www.zhihu.com/</a> .
You need to create a crawler class that extends BreadthCrawler.</p>

<pre><code>public class ZhihuCrawler extends BreadthCrawler{

    /**
     * This function is called when a page is fetched and
     * ready to be processed by your program.       
    */
    @Override
    public void visit(Page page) {
        String question_regex="^http://www.zhihu.com/question/[0-9]+";         
        if(Pattern.matches(question_regex, page.getUrl())){              
            System.out.println("processing "+page.getUrl());

            /*extract title of the page*/
            String title=page.getDoc().title();
            System.out.println(title);

            /*extract the content of question*/
            String question=page.getDoc().select("div[id=zh-question-detail]").text();
            System.out.println(question);

        }
    }

    /**
     * start crawling
    */
    public static void main(String[] args) throws IOException{  
        ZhihuCrawler crawler=new ZhihuCrawler();
        crawler.addSeed("http://www.zhihu.com/question/21003086");
        crawler.addRegex("http://www.zhihu.com/.*");
        /*start the crawler with depth=5*/
        crawler.start(5);  
    }


}
</code></pre>

<p>As can be seen in the above code,there are one function that should be overridden:</p>

<ul>
<li>
<strong>visit(Page page):</strong> This function is called after the content of a URL is downloaded successfully.You can easily get the url,text of the downloaded page.If the Content-Type of the downloaded page is text/html,you could also get the document and html of the page.The document is a dom tree parsed by JSOUP.The html is a String decoded by detected charset.Page is an instance of cn.edu.hfut.dmic.webcollector.model.Page

<ul>
<li>page.getUrl() returns the url of the downloaded page</li>
<li>page.getContent() returns the origin data of the page</li>
<li>page.getDoc() returns an instance of org.jsoup.nodes.Document</li>
<li>page.getResponse() returns the http response of the page</li>
<li>page.getFetchTime() returns the time this page be fetched at  generated by System.currentTimeMillis()</li>
</ul>
</li>
</ul><p><strong>中文教程:</strong> <a href="https://github.com/CrawlScript/WebCollector/blob/master/README.zh-cn.md">https://github.com/CrawlScript/WebCollector/blob/master/README.zh-cn.md</a></p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Webcollector maintained by <a href="https://github.com/CrawlScript">CrawlScript</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
